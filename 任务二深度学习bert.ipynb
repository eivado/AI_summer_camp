{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed4cde3-de72-4113-80f3-05748e123a69",
   "metadata": {},
   "source": [
    "> 使用预训练的BERT模型进行建模的思路步骤如下：\n",
    ">\n",
    "> - 数据预处理：首先，对文本数据进行预处理，包括文本清洗（如去除特殊字符、标点符号）、分词等操作。可以使用常见的NLP工具包（如NLTK或spaCy）来辅助进行预处理。\n",
    "> - 构建训练所需的dataloader与dataset，构建Dataset类时，需要定义三个方法__init__，__getitem__， __len__，其中__init__方法完成类初始化，__getitem__要求返回返回内容和label，__len__方法返回数据长度\n",
    "> - 构造Dataloader，在其中完成对句子进行编码、填充、组装batch等动作：\n",
    "> - 定义预测模型利用预训练的BERT模型来解决文本二分类任务，我们将使用BERT模型编码中的[CLS]向量来完成二分类任务[CLS]就是classification的意思，可以理解为用于下游的分类任务。\n",
    "\n",
    "> 主要用于以下两种任务：\n",
    "\n",
    "> - 单文本分类任务：对于文本分类任务，BERT模型在文本前插入一个[CLS]符号，并将该符号对应的输出向量作为整篇文本的语义表示，用于文本分类，如下图所示。可以理解为：与文本中已有的其它字/词相比，这个无明显语义信息的符号会更“公平”地融合文本中各个字/词的语义信息。\n",
    ">\n",
    "> - 在模型设计中思路就体现为我们取出文本数据经过向量化后的[CLS]向量，然后经过二分类预测层得到最终的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907637-44f5-4981-9a80-ce8d3e7f4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = self.bert(**src).last_hidden_state[:, 0, :]\n",
    "self.predictor(outputs)\n",
    "self.predictor = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd4265-89b2-46c8-a792-f09fc6d2a9dc",
   "metadata": {},
   "source": [
    "- 模型训练和评估：使用训练集对选定的机器学习模型进行训练，然后使用测试集进行评估。评估指标可以选择准确率、精确率、召回率、F1值等。\n",
    "- 调参优化：如果模型效果不理想，可以尝试调整特征提取的参数（如词频阈值、词袋大小等）或机器学习模型的参数，以获得更好的性能。\n",
    "- 在这个进阶实践中，我们使用深度学习方法，一般会遵循以下流程：\n",
    "  数据收集与准备->模型定义->模型训练->模型评估与优化->结果输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6950e3-213c-42ee-8071-62858b0b5353",
   "metadata": {},
   "source": [
    "##### 导入我们本次Baseline代码所需的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aec2683-6df7-4c8d-9fb4-de5b5fdada2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 相关库\n",
    "#导入前置依赖\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 用于加载bert模型的分词器\n",
    "from transformers import AutoTokenizer\n",
    "# 用于加载bert模型\n",
    "from transformers import BertModel\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bda146-091b-4f11-8a7c-c79abac4e6a9",
   "metadata": {},
   "source": [
    "##### 设置全局配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd038ceb-475b-46a4-9570-b2444e951d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "# 文本的最大长度\n",
    "text_max_length = 128\n",
    "# 总训练的epochs数，我只是随便定义了个数\n",
    "epochs = 100\n",
    "# 学习率\n",
    "lr = 3e-5\n",
    "# 取多少训练集的数据作为验证集\n",
    "validation_ratio = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 每多少步，打印一次loss\n",
    "log_per_step = 50\n",
    "\n",
    "# 数据集所在位置\n",
    "dataset_dir = Path(\"/root/autodl-tmp/gitdir/ai_summer_camp/基于论文摘要的文本分类与关键词抽取挑战赛公开数据\")\n",
    "os.makedirs(dataset_dir) if not os.path.exists(dataset_dir) else ''\n",
    "\n",
    "# 模型存储路径\n",
    "model_dir = Path(\"/root/autodl-tmp/gitdir/ai_summer_camp/model/bert_checkpoints\")\n",
    "# 如果模型目录不存在，则创建一个\n",
    "os.makedirs(model_dir) if not os.path.exists(model_dir) else ''\n",
    "\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089a875-ced6-46f3-96bf-f68bd5cc42ca",
   "metadata": {},
   "source": [
    "##### 数据收集与准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bfd13-e05f-4792-a518-658344105c05",
   "metadata": {},
   "source": [
    "> 在赛题主页下载数据，读取数据集，数据预处理（考虑数据扩增）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eae173f-3aaa-40ab-a73b-0e6863d618da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tobacco Consumption and High-Sensitivity Cardi...\n",
       "1    Approaching towards sustainable supply chain u...\n",
       "2    Does globalization matter for ecological footp...\n",
       "3    Myths and Misconceptions About University Stud...\n",
       "4    Antioxidant Status of Rat Liver Mitochondria u...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据集，进行数据处理\n",
    "\n",
    "pd_train_data = pd.read_csv('/root/autodl-tmp/gitdir/ai_summer_camp/基于论文摘要的文本分类与关键词抽取挑战赛公开数据/train.csv')\n",
    "pd_train_data['title'] = pd_train_data['title'].fillna('')\n",
    "pd_train_data['abstract'] = pd_train_data['abstract'].fillna('')\n",
    "\n",
    "test_data = pd.read_csv('/root/autodl-tmp/gitdir/ai_summer_camp/基于论文摘要的文本分类与关键词抽取挑战赛测试集B/testB.csv')\n",
    "test_data['title'] = test_data['title'].fillna('')\n",
    "test_data['abstract'] = test_data['abstract'].fillna('')\n",
    "pd_train_data['text'] = pd_train_data['title'].fillna('') + ' ' +  pd_train_data['author'].fillna('') + ' ' + pd_train_data['abstract'].fillna('')+ ' ' + pd_train_data['Keywords'].fillna('')\n",
    "test_data['text'] = test_data['title'].fillna('') + ' ' +  test_data['author'].fillna('') + ' ' + test_data['abstract'].fillna('')+ ' ' + pd_train_data['Keywords'].fillna('')\n",
    "#test['Keywords'] = test['title'].fillna('')\n",
    "\n",
    "test_data['title'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f5a616-b3f1-4a8a-bb27-8da4824a8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练集中随机采样测试集\n",
    "validation_data = pd_train_data.sample(frac=validation_ratio)\n",
    "train_data = pd_train_data[~pd_train_data.index.isin(validation_data.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194f3f7c-9027-48e4-b488-87fc828dc339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uuid' 'title' 'author' 'abstract' 'Keywords' 'label' 'text']\n",
      "['uuid' 'title' 'author' 'abstract' 'text']\n"
     ]
    }
   ],
   "source": [
    "#查看训练数据集的列名\n",
    "print(pd_train_data.columns.values)\n",
    "#查看测试数据集的列名\n",
    "print(test_data.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272c4ea-343e-49ea-b59d-e6f62b384ace",
   "metadata": {},
   "source": [
    "##### 构建训练所需的dataloader与dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31b5f4-e5c3-462b-bf99-00362c1eeb0f",
   "metadata": {},
   "source": [
    "###### 定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ccb030a-55f7-4884-8880-349b9e492c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Dataset\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        # 拿到对应的数据\n",
    "        if mode == 'train':\n",
    "            self.dataset = train_data\n",
    "        elif mode == 'validation':\n",
    "            self.dataset = validation_data\n",
    "        elif mode == 'test':\n",
    "            # 如果是测试模式，则返回内容和uuid。拿uuid做target主要是方便后面写入结果。\n",
    "            self.dataset = test_data\n",
    "        else:\n",
    "            raise Exception(\"Unknown mode {}\".format(mode))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 取第index条\n",
    "        data = self.dataset.iloc[index]\n",
    "        # 取其内容\n",
    "        text = data['text']\n",
    "        # 根据状态返回内容\n",
    "        if self.mode == 'test':\n",
    "            # 如果是test，将uuid做为target\n",
    "            label = data['uuid']\n",
    "        else:\n",
    "            label = data['label']\n",
    "        # 返回内容和label\n",
    "        return text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6970b3f-e7cf-4aef-82d0-25ff763dda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset('train')\n",
    "validation_dataset = MyDataset('validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a9e893-3b6b-49f9-88bb-3aa6579e2d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accessible Visual Artworks for Blind and Visually Impaired People: Comparing a Multimodal Approach with Tactile Graphics Quero, Luis Cavazos; Bartolome, Jorge Iranzo; Cho, Jundong Despite the use of tactile graphics and audio guides, blind and visually impaired people still face challenges to experience and understand visual artworks independently at art exhibitions. Art museums and other art places are increasingly exploring the use of interactive guides to make their collections more accessible. In this work, we describe our approach to an interactive multimodal guide prototype that uses audio and tactile modalities to improve the autonomous access to information and experience of visual artworks. The prototype is composed of a touch-sensitive 2.5D artwork relief model that can be freely explored by touch. Users can access localized verbal descriptions and audio by performing touch gestures on the surface while listening to themed background music along. We present the design requirements derived from a formative study realized with the help of eight blind and visually impaired participants, art museum and gallery staff, and artists. We extended the formative study by organizing two accessible art exhibitions. There, eighteen participants evaluated and compared multimodal and tactile graphic accessible exhibits. Results from a usability survey indicate that our multimodal approach is simple, easy to use, and improves confidence and independence when exploring visual artworks. accessibility technology; multimodal interaction; auditory interface; touch interface; vision impairment',\n",
       " 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e210e-463a-4521-9181-0367223619e6",
   "metadata": {},
   "source": [
    "###### 构造Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd37c33b-71c7-4caa-beb6-ea9a1cdc1d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d623c367e44558a47eb8e8856053fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e769c557b247d9933e37da79cc9c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a0aa37677846b3a7e8de862e845742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa6c0a06434f1e98fddcbc6b8077ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#获取Bert预训练模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f732534-e9f7-4c10-ae7a-0b53b0903524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#接着构造我们的Dataloader。\n",
    "#我们需要定义一下collate_fn，在其中完成对句子进行编码、填充、组装batch等动作：\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    将一个batch的文本句子转成tensor，并组成batch。\n",
    "    :param batch: 一个batch的句子，例如: [('推文', target), ('推文', target), ...]\n",
    "    :return: 处理后的结果，例如：\n",
    "             src: {'input_ids': tensor([[ 101, ..., 102, 0, 0, ...], ...]), 'attention_mask': tensor([[1, ..., 1, 0, ...], ...])}\n",
    "             target：[1, 1, 0, ...]\n",
    "    \"\"\"\n",
    "    text, label = zip(*batch)\n",
    "    text, label = list(text), list(label)\n",
    "\n",
    "    # src是要送给bert的，所以不需要特殊处理，直接用tokenizer的结果即可\n",
    "    # padding='max_length' 不够长度的进行填充\n",
    "    # truncation=True 长度过长的进行裁剪\n",
    "    src = tokenizer(text, padding='max_length', max_length=text_max_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    return src, torch.LongTensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c29821-f861-41e3-b830-047e2934c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaeb2d93-2d58-4303-a51a-96910a7b793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'input_ids': tensor([[  101,  7605,  4874,  ..., 10624,  6914,   102],\n",
      "        [  101,  2309,  1011,  ...,  5679,  1999,   102],\n",
      "        [  101, 27218,  1011,  ..., 11004,  4609,   102],\n",
      "        ...,\n",
      "        [  101,  7987,  3593,  ...,  2122,  7876,   102],\n",
      "        [  101,  2156,  2129,  ...,  6454,  1010,   102],\n",
      "        [  101, 21598, 16913,  ...,  1058, 18939,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "targets: tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# 里面iter 是迭代器，next是输出迭代器的下一个值\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"targets:\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb2206-1321-4697-8bac-d104da8aecd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7d568b-1785-4266-827a-c681b0955c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义预测模型，该模型由bert模型加上最后的预测层组成\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 加载bert模型\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased', mirror='tuna')\n",
    "\n",
    "        # 最后的预测层\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        :param src: 分词后的推文数据\n",
    "        \"\"\"\n",
    "\n",
    "        # 将src直接序列解包传入bert，因为bert和tokenizer是一套的，所以可以这么做。\n",
    "        # 得到encoder的输出，用最前面[CLS]的输出作为最终线性层的输入\n",
    "        outputs = self.bert(**src).last_hidden_state[:, 0, :]\n",
    "\n",
    "        # 使用线性层来做最终的预测\n",
    "        return self.predictor(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccc328a-57ac-4028-9e50-661655737744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d684e466769149ccb50ccc0e9162193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8536f-23ad-4bdc-9e91-ac5991a2803e",
   "metadata": {},
   "source": [
    "##### 定义出损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c086afc-37ed-4f5c-ae8a-b2818100e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义出损失函数和优化器。这里使用Binary Cross Entropy：\n",
    "criteria = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ffcd0fe-d4fb-4d29-83c0-cd2c9608fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于inputs是字典类型的，定义一个辅助函数帮助to(device)\n",
    "# Python 字典(Dictionary) items() 函数以列表返回可遍历的(键, 值) 元组数组。\n",
    "def to_device(dict_tensors):\n",
    "    result_tensors = {}\n",
    "    for key, value in dict_tensors.items():\n",
    "        result_tensors[key] = value.to(device)\n",
    "    return result_tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3d481-36a7-4029-85c6-5196f1c49e91",
   "metadata": {},
   "source": [
    "##### 定义验证方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34db9057-7058-43a4-be6e-cfba00381f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个验证方法，获取到验证集的精准率和loss\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_correct = 0\n",
    "    for inputs, targets in validation_loader:\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criteria(outputs.view(-1), targets.float())\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        correct_num = (((outputs >= 0.5).float() * 1).flatten() == targets).sum()\n",
    "        total_correct += correct_num\n",
    "\n",
    "    return total_correct / len(validation_dataset), total_loss / len(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c25f7e-0a70-4baa-9eb4-b2ee502a5618",
   "metadata": {},
   "source": [
    "##### 模型训练、评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d4ebc90-8478-48f0-8b2e-5d67e2e8824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Step: 49/338, total loss:16.5111\n",
      "Epoch 1/100, Step: 99/338, total loss:6.5136\n",
      "Epoch 1/100, Step: 149/338, total loss:5.6502\n",
      "Epoch 1/100, Step: 199/338, total loss:6.6170\n",
      "Epoch 1/100, Step: 249/338, total loss:5.2193\n",
      "Epoch 1/100, Step: 299/338, total loss:3.8585\n",
      "Epoch 1, accuracy: 0.9617, validation loss: 0.0078\n",
      "Epoch 2/100, Step: 11/338, total loss:6.6585\n",
      "Epoch 2/100, Step: 61/338, total loss:3.4986\n",
      "Epoch 2/100, Step: 111/338, total loss:3.1230\n",
      "Epoch 2/100, Step: 161/338, total loss:4.4627\n",
      "Epoch 2/100, Step: 211/338, total loss:3.9473\n",
      "Epoch 2/100, Step: 261/338, total loss:4.6345\n",
      "Epoch 2/100, Step: 311/338, total loss:3.9789\n",
      "Epoch 2, accuracy: 0.9583, validation loss: 0.0063\n",
      "Epoch 3/100, Step: 23/338, total loss:2.7229\n",
      "Epoch 3/100, Step: 73/338, total loss:2.8375\n",
      "Epoch 3/100, Step: 123/338, total loss:2.6576\n",
      "Epoch 3/100, Step: 173/338, total loss:2.6944\n",
      "Epoch 3/100, Step: 223/338, total loss:2.0251\n",
      "Epoch 3/100, Step: 273/338, total loss:2.9500\n",
      "Epoch 3/100, Step: 323/338, total loss:3.1479\n",
      "Epoch 3, accuracy: 0.9617, validation loss: 0.0071\n",
      "Epoch 4/100, Step: 35/338, total loss:1.2853\n",
      "Epoch 4/100, Step: 85/338, total loss:1.6378\n",
      "Epoch 4/100, Step: 135/338, total loss:1.1992\n",
      "Epoch 4/100, Step: 185/338, total loss:2.1435\n",
      "Epoch 4/100, Step: 235/338, total loss:2.1577\n",
      "Epoch 4/100, Step: 285/338, total loss:1.9917\n",
      "Epoch 4/100, Step: 335/338, total loss:2.7231\n",
      "Epoch 4, accuracy: 0.9650, validation loss: 0.0067\n",
      "Epoch 5/100, Step: 47/338, total loss:1.8723\n",
      "Epoch 5/100, Step: 97/338, total loss:1.5255\n",
      "Epoch 5/100, Step: 147/338, total loss:1.1029\n",
      "Epoch 5/100, Step: 197/338, total loss:0.9438\n",
      "Epoch 5/100, Step: 247/338, total loss:2.0640\n",
      "Epoch 5/100, Step: 297/338, total loss:1.2314\n",
      "Epoch 5, accuracy: 0.9683, validation loss: 0.0062\n",
      "Epoch 6/100, Step: 9/338, total loss:2.1457\n",
      "Epoch 6/100, Step: 59/338, total loss:0.3133\n",
      "Epoch 6/100, Step: 109/338, total loss:0.5599\n",
      "Epoch 6/100, Step: 159/338, total loss:1.0730\n",
      "Epoch 6/100, Step: 209/338, total loss:1.4455\n",
      "Epoch 6/100, Step: 259/338, total loss:0.8030\n",
      "Epoch 6/100, Step: 309/338, total loss:0.9237\n",
      "Epoch 6, accuracy: 0.9600, validation loss: 0.0087\n",
      "Epoch 7/100, Step: 21/338, total loss:0.6765\n",
      "Epoch 7/100, Step: 71/338, total loss:0.1498\n",
      "Epoch 7/100, Step: 121/338, total loss:0.5111\n",
      "Epoch 7/100, Step: 171/338, total loss:0.0520\n",
      "Epoch 7/100, Step: 221/338, total loss:0.3866\n",
      "Epoch 7/100, Step: 271/338, total loss:0.4628\n",
      "Epoch 7/100, Step: 321/338, total loss:0.4050\n",
      "Epoch 7, accuracy: 0.9683, validation loss: 0.0122\n",
      "Epoch 8/100, Step: 33/338, total loss:0.0795\n",
      "Epoch 8/100, Step: 83/338, total loss:0.1799\n",
      "Epoch 8/100, Step: 133/338, total loss:0.5296\n",
      "Epoch 8/100, Step: 183/338, total loss:0.0456\n",
      "Epoch 8/100, Step: 233/338, total loss:0.0244\n",
      "Epoch 8/100, Step: 283/338, total loss:0.9768\n",
      "Epoch 8/100, Step: 333/338, total loss:0.7839\n",
      "Epoch 8, accuracy: 0.9650, validation loss: 0.0123\n",
      "Epoch 9/100, Step: 45/338, total loss:1.1989\n",
      "Epoch 9/100, Step: 95/338, total loss:0.6155\n",
      "Epoch 9/100, Step: 145/338, total loss:0.2261\n",
      "Epoch 9/100, Step: 195/338, total loss:1.0052\n",
      "Epoch 9/100, Step: 245/338, total loss:0.1071\n",
      "Epoch 9/100, Step: 295/338, total loss:0.6763\n",
      "Epoch 9, accuracy: 0.9650, validation loss: 0.0100\n",
      "Epoch 10/100, Step: 7/338, total loss:1.4764\n",
      "Epoch 10/100, Step: 57/338, total loss:0.2720\n",
      "Epoch 10/100, Step: 107/338, total loss:1.3399\n",
      "Epoch 10/100, Step: 157/338, total loss:0.5250\n",
      "Epoch 10/100, Step: 207/338, total loss:0.9806\n",
      "Epoch 10/100, Step: 257/338, total loss:1.3080\n",
      "Epoch 10/100, Step: 307/338, total loss:0.0897\n",
      "Epoch 10, accuracy: 0.9633, validation loss: 0.0096\n",
      "Epoch 11/100, Step: 19/338, total loss:0.2629\n",
      "Epoch 11/100, Step: 69/338, total loss:0.2352\n",
      "Epoch 11/100, Step: 119/338, total loss:0.5197\n",
      "Epoch 11/100, Step: 169/338, total loss:0.3109\n",
      "Epoch 11/100, Step: 219/338, total loss:0.2607\n",
      "Epoch 11/100, Step: 269/338, total loss:0.7206\n",
      "Epoch 11/100, Step: 319/338, total loss:0.0722\n",
      "Epoch 11, accuracy: 0.9550, validation loss: 0.0155\n",
      "Epoch 12/100, Step: 31/338, total loss:0.1803\n",
      "Epoch 12/100, Step: 81/338, total loss:0.0255\n",
      "Epoch 12/100, Step: 131/338, total loss:0.0171\n",
      "Epoch 12/100, Step: 181/338, total loss:0.0106\n",
      "Epoch 12/100, Step: 231/338, total loss:0.0101\n",
      "Epoch 12/100, Step: 281/338, total loss:1.6166\n",
      "Epoch 12/100, Step: 331/338, total loss:0.6741\n",
      "Epoch 12, accuracy: 0.9583, validation loss: 0.0137\n",
      "Epoch 13/100, Step: 43/338, total loss:0.2882\n",
      "Epoch 13/100, Step: 93/338, total loss:0.0974\n",
      "Epoch 13/100, Step: 143/338, total loss:0.0477\n",
      "Epoch 13/100, Step: 193/338, total loss:0.0750\n",
      "Epoch 13/100, Step: 243/338, total loss:1.7048\n",
      "Epoch 13/100, Step: 293/338, total loss:0.6897\n",
      "Epoch 13, accuracy: 0.9600, validation loss: 0.0100\n",
      "Epoch 14/100, Step: 5/338, total loss:0.4646\n",
      "Epoch 14/100, Step: 55/338, total loss:0.0837\n",
      "Epoch 14/100, Step: 105/338, total loss:0.0192\n",
      "Epoch 14/100, Step: 155/338, total loss:0.3482\n",
      "Epoch 14/100, Step: 205/338, total loss:1.8718\n",
      "Epoch 14/100, Step: 255/338, total loss:0.4322\n",
      "Epoch 14/100, Step: 305/338, total loss:0.2541\n",
      "Epoch 14, accuracy: 0.9600, validation loss: 0.0143\n",
      "Epoch 15/100, Step: 17/338, total loss:0.3707\n",
      "Epoch 15/100, Step: 67/338, total loss:0.0159\n",
      "Epoch 15/100, Step: 117/338, total loss:0.7430\n",
      "Epoch 15/100, Step: 167/338, total loss:0.2807\n",
      "Epoch 15/100, Step: 217/338, total loss:0.0986\n",
      "Epoch 15/100, Step: 267/338, total loss:0.1203\n",
      "Epoch 15/100, Step: 317/338, total loss:0.0166\n",
      "Epoch 15, accuracy: 0.9583, validation loss: 0.0170\n",
      "Epoch 16/100, Step: 29/338, total loss:0.0148\n",
      "Epoch 16/100, Step: 79/338, total loss:0.0094\n",
      "Epoch 16/100, Step: 129/338, total loss:0.0088\n",
      "Epoch 16/100, Step: 179/338, total loss:0.0067\n",
      "Epoch 16/100, Step: 229/338, total loss:0.0084\n",
      "Epoch 16/100, Step: 279/338, total loss:0.0087\n",
      "Epoch 16/100, Step: 329/338, total loss:0.0075\n",
      "Epoch 16, accuracy: 0.9583, validation loss: 0.0171\n",
      "Epoch 17/100, Step: 41/338, total loss:0.0054\n",
      "Epoch 17/100, Step: 91/338, total loss:0.0049\n",
      "Epoch 17/100, Step: 141/338, total loss:0.0051\n",
      "Epoch 17/100, Step: 191/338, total loss:0.0039\n",
      "Epoch 17/100, Step: 241/338, total loss:0.0044\n",
      "Epoch 17/100, Step: 291/338, total loss:0.0038\n",
      "Epoch 17, accuracy: 0.9583, validation loss: 0.0183\n",
      "Epoch 18/100, Step: 3/338, total loss:0.0039\n",
      "Epoch 18/100, Step: 53/338, total loss:0.0035\n",
      "Epoch 18/100, Step: 103/338, total loss:0.0032\n",
      "Epoch 18/100, Step: 153/338, total loss:0.0055\n",
      "Epoch 18/100, Step: 203/338, total loss:0.0042\n",
      "Epoch 18/100, Step: 253/338, total loss:0.0028\n",
      "Epoch 18/100, Step: 303/338, total loss:0.0025\n",
      "Epoch 18, accuracy: 0.9583, validation loss: 0.0175\n",
      "Epoch 19/100, Step: 15/338, total loss:0.0026\n",
      "Epoch 19/100, Step: 65/338, total loss:0.0025\n",
      "Epoch 19/100, Step: 115/338, total loss:0.0023\n",
      "Epoch 19/100, Step: 165/338, total loss:0.0023\n",
      "Epoch 19/100, Step: 215/338, total loss:0.0021\n",
      "Epoch 19/100, Step: 265/338, total loss:0.0020\n",
      "Epoch 19/100, Step: 315/338, total loss:0.0020\n",
      "Epoch 19, accuracy: 0.9583, validation loss: 0.0181\n",
      "Epoch 20/100, Step: 27/338, total loss:0.0019\n",
      "Epoch 20/100, Step: 77/338, total loss:0.0018\n",
      "Epoch 20/100, Step: 127/338, total loss:0.0053\n",
      "Epoch 20/100, Step: 177/338, total loss:0.0017\n",
      "Epoch 20/100, Step: 227/338, total loss:0.0016\n",
      "Epoch 20/100, Step: 277/338, total loss:0.0016\n",
      "Epoch 20/100, Step: 327/338, total loss:0.0016\n",
      "Epoch 20, accuracy: 0.9667, validation loss: 0.0168\n",
      "Epoch 21/100, Step: 39/338, total loss:0.0014\n",
      "Epoch 21/100, Step: 89/338, total loss:0.0047\n",
      "Epoch 21/100, Step: 139/338, total loss:0.0015\n",
      "Epoch 21/100, Step: 189/338, total loss:0.0060\n",
      "Epoch 21/100, Step: 239/338, total loss:0.5043\n",
      "Epoch 21/100, Step: 289/338, total loss:1.1498\n",
      "Epoch 21, accuracy: 0.9600, validation loss: 0.0111\n",
      "Epoch 22/100, Step: 1/338, total loss:1.1551\n",
      "Epoch 22/100, Step: 51/338, total loss:0.3664\n",
      "Epoch 22/100, Step: 101/338, total loss:0.2692\n",
      "Epoch 22/100, Step: 151/338, total loss:0.0207\n",
      "Epoch 22/100, Step: 201/338, total loss:1.4188\n",
      "Epoch 22/100, Step: 251/338, total loss:0.3495\n",
      "Epoch 22/100, Step: 301/338, total loss:0.0233\n",
      "Epoch 22, accuracy: 0.9617, validation loss: 0.0137\n",
      "Epoch 23/100, Step: 13/338, total loss:0.0210\n",
      "Epoch 23/100, Step: 63/338, total loss:0.1644\n",
      "Epoch 23/100, Step: 113/338, total loss:0.7696\n",
      "Epoch 23/100, Step: 163/338, total loss:0.1046\n",
      "Epoch 23/100, Step: 213/338, total loss:0.0212\n",
      "Epoch 23/100, Step: 263/338, total loss:2.1119\n",
      "Epoch 23/100, Step: 313/338, total loss:0.3476\n",
      "Epoch 23, accuracy: 0.9617, validation loss: 0.0156\n",
      "Epoch 24/100, Step: 25/338, total loss:0.1068\n",
      "Epoch 24/100, Step: 75/338, total loss:0.0242\n",
      "Epoch 24/100, Step: 125/338, total loss:0.4393\n",
      "Epoch 24/100, Step: 175/338, total loss:1.0047\n",
      "Epoch 24/100, Step: 225/338, total loss:0.2670\n",
      "Epoch 24/100, Step: 275/338, total loss:0.0342\n",
      "Epoch 24/100, Step: 325/338, total loss:0.4505\n",
      "Epoch 24, accuracy: 0.9550, validation loss: 0.0150\n",
      "Epoch 25/100, Step: 37/338, total loss:1.2300\n",
      "Epoch 25/100, Step: 87/338, total loss:0.3769\n",
      "Epoch 25/100, Step: 137/338, total loss:0.0628\n",
      "Epoch 25/100, Step: 187/338, total loss:0.0550\n",
      "Epoch 25/100, Step: 237/338, total loss:0.6662\n",
      "Epoch 25/100, Step: 287/338, total loss:0.4561\n",
      "Epoch 25/100, Step: 337/338, total loss:0.9723\n",
      "Epoch 25, accuracy: 0.9550, validation loss: 0.0188\n",
      "Epoch 26/100, Step: 49/338, total loss:0.4086\n",
      "Epoch 26/100, Step: 99/338, total loss:0.0339\n",
      "Epoch 26/100, Step: 149/338, total loss:0.0177\n",
      "Epoch 26/100, Step: 199/338, total loss:0.0732\n",
      "Epoch 26/100, Step: 249/338, total loss:0.3936\n",
      "Epoch 26/100, Step: 299/338, total loss:0.6537\n",
      "Epoch 26, accuracy: 0.9583, validation loss: 0.0144\n",
      "Epoch 27/100, Step: 11/338, total loss:0.2038\n",
      "Epoch 27/100, Step: 61/338, total loss:0.0277\n",
      "Epoch 27/100, Step: 111/338, total loss:0.0354\n",
      "Epoch 27/100, Step: 161/338, total loss:0.0084\n",
      "Epoch 27/100, Step: 211/338, total loss:0.8855\n",
      "Epoch 27/100, Step: 261/338, total loss:0.3224\n",
      "Epoch 27/100, Step: 311/338, total loss:0.1140\n",
      "Epoch 27, accuracy: 0.9550, validation loss: 0.0212\n",
      "Epoch 28/100, Step: 23/338, total loss:0.9713\n",
      "Epoch 28/100, Step: 73/338, total loss:0.0393\n",
      "Epoch 28/100, Step: 123/338, total loss:0.0590\n",
      "Epoch 28/100, Step: 173/338, total loss:0.7696\n",
      "Epoch 28/100, Step: 223/338, total loss:0.2395\n",
      "Epoch 28/100, Step: 273/338, total loss:0.0477\n",
      "Epoch 28/100, Step: 323/338, total loss:0.0091\n",
      "Epoch 28, accuracy: 0.9583, validation loss: 0.0171\n",
      "Epoch 29/100, Step: 35/338, total loss:0.0082\n",
      "Epoch 29/100, Step: 85/338, total loss:0.2030\n",
      "Epoch 29/100, Step: 135/338, total loss:0.0816\n",
      "Epoch 29/100, Step: 185/338, total loss:1.6861\n",
      "Epoch 29/100, Step: 235/338, total loss:0.1146\n",
      "Epoch 29/100, Step: 285/338, total loss:0.7318\n",
      "Epoch 29/100, Step: 335/338, total loss:0.2292\n",
      "Epoch 29, accuracy: 0.9600, validation loss: 0.0108\n",
      "Epoch 30/100, Step: 47/338, total loss:0.1109\n",
      "Epoch 30/100, Step: 97/338, total loss:0.0557\n",
      "Epoch 30/100, Step: 147/338, total loss:0.3178\n",
      "Epoch 30/100, Step: 197/338, total loss:0.1667\n",
      "Epoch 30/100, Step: 247/338, total loss:0.0163\n",
      "Epoch 30/100, Step: 297/338, total loss:0.0188\n",
      "Epoch 30, accuracy: 0.9600, validation loss: 0.0178\n",
      "Epoch 31/100, Step: 9/338, total loss:0.0049\n",
      "Epoch 31/100, Step: 59/338, total loss:0.0059\n",
      "Epoch 31/100, Step: 109/338, total loss:0.0034\n",
      "Epoch 31/100, Step: 159/338, total loss:0.0049\n",
      "Epoch 31/100, Step: 209/338, total loss:0.0435\n",
      "Epoch 31/100, Step: 259/338, total loss:0.6641\n",
      "Epoch 31/100, Step: 309/338, total loss:0.0192\n",
      "Epoch 31, accuracy: 0.9667, validation loss: 0.0151\n",
      "Epoch 32/100, Step: 21/338, total loss:0.0924\n",
      "Epoch 32/100, Step: 71/338, total loss:0.2696\n",
      "Epoch 32/100, Step: 121/338, total loss:0.0894\n",
      "Epoch 32/100, Step: 171/338, total loss:0.0706\n",
      "Epoch 32/100, Step: 221/338, total loss:0.0139\n",
      "Epoch 32/100, Step: 271/338, total loss:0.2118\n",
      "Epoch 32/100, Step: 321/338, total loss:0.1966\n",
      "Epoch 32, accuracy: 0.9617, validation loss: 0.0170\n",
      "Epoch 33/100, Step: 33/338, total loss:0.0106\n",
      "Epoch 33/100, Step: 83/338, total loss:0.0786\n",
      "Epoch 33/100, Step: 133/338, total loss:0.0594\n",
      "Epoch 33/100, Step: 183/338, total loss:0.0030\n",
      "Epoch 33/100, Step: 233/338, total loss:0.0029\n",
      "Epoch 33/100, Step: 283/338, total loss:0.0028\n",
      "Epoch 33/100, Step: 333/338, total loss:0.0054\n",
      "Epoch 33, accuracy: 0.9617, validation loss: 0.0192\n",
      "Epoch 34/100, Step: 45/338, total loss:0.0024\n",
      "Epoch 34/100, Step: 95/338, total loss:0.0022\n",
      "Epoch 34/100, Step: 145/338, total loss:0.0030\n",
      "Epoch 34/100, Step: 195/338, total loss:0.0239\n",
      "Epoch 34/100, Step: 245/338, total loss:0.0017\n",
      "Epoch 34/100, Step: 295/338, total loss:0.0016\n",
      "Epoch 34, accuracy: 0.9600, validation loss: 0.0212\n",
      "Epoch 35/100, Step: 7/338, total loss:0.0017\n",
      "Epoch 35/100, Step: 57/338, total loss:0.0017\n",
      "Epoch 35/100, Step: 107/338, total loss:0.0014\n",
      "Epoch 35/100, Step: 157/338, total loss:0.0029\n",
      "Epoch 35/100, Step: 207/338, total loss:0.0015\n",
      "Epoch 35/100, Step: 257/338, total loss:0.0013\n",
      "Epoch 35/100, Step: 307/338, total loss:0.0012\n",
      "Epoch 35, accuracy: 0.9633, validation loss: 0.0216\n",
      "Epoch 36/100, Step: 19/338, total loss:0.0012\n",
      "Epoch 36/100, Step: 69/338, total loss:0.0012\n",
      "Epoch 36/100, Step: 119/338, total loss:0.0014\n",
      "Epoch 36/100, Step: 169/338, total loss:0.0011\n",
      "Epoch 36/100, Step: 219/338, total loss:0.0011\n",
      "Epoch 36/100, Step: 269/338, total loss:0.0011\n",
      "Epoch 36/100, Step: 319/338, total loss:0.0011\n",
      "Epoch 36, accuracy: 0.9633, validation loss: 0.0221\n",
      "Epoch 37/100, Step: 31/338, total loss:0.0011\n",
      "Epoch 37/100, Step: 81/338, total loss:0.0010\n",
      "Epoch 37/100, Step: 131/338, total loss:0.0009\n",
      "Epoch 37/100, Step: 181/338, total loss:0.0010\n",
      "Epoch 37/100, Step: 231/338, total loss:0.0033\n",
      "Epoch 37/100, Step: 281/338, total loss:0.0009\n",
      "Epoch 37/100, Step: 331/338, total loss:0.0008\n",
      "Epoch 37, accuracy: 0.9617, validation loss: 0.0222\n",
      "Epoch 38/100, Step: 43/338, total loss:0.0008\n",
      "Epoch 38/100, Step: 93/338, total loss:0.0008\n",
      "Epoch 38/100, Step: 143/338, total loss:0.0008\n",
      "Epoch 38/100, Step: 193/338, total loss:0.0009\n",
      "Epoch 38/100, Step: 243/338, total loss:0.0007\n",
      "Epoch 38/100, Step: 293/338, total loss:0.0007\n",
      "Epoch 38, accuracy: 0.9617, validation loss: 0.0227\n",
      "Epoch 39/100, Step: 5/338, total loss:0.0007\n",
      "Epoch 39/100, Step: 55/338, total loss:0.0009\n",
      "Epoch 39/100, Step: 105/338, total loss:0.0006\n",
      "Epoch 39/100, Step: 155/338, total loss:0.0006\n",
      "Epoch 39/100, Step: 205/338, total loss:0.0006\n",
      "Epoch 39/100, Step: 255/338, total loss:0.0006\n",
      "Epoch 39/100, Step: 305/338, total loss:0.0006\n",
      "Epoch 39, accuracy: 0.9617, validation loss: 0.0231\n",
      "Epoch 40/100, Step: 17/338, total loss:0.0006\n",
      "Epoch 40/100, Step: 67/338, total loss:0.0006\n",
      "Epoch 40/100, Step: 117/338, total loss:0.0006\n",
      "Epoch 40/100, Step: 167/338, total loss:0.0006\n",
      "Epoch 40/100, Step: 217/338, total loss:0.0005\n",
      "Epoch 40/100, Step: 267/338, total loss:0.0008\n",
      "Epoch 40/100, Step: 317/338, total loss:0.0005\n",
      "Epoch 40, accuracy: 0.9617, validation loss: 0.0238\n",
      "Epoch 41/100, Step: 29/338, total loss:0.0005\n",
      "Epoch 41/100, Step: 79/338, total loss:0.0005\n",
      "Epoch 41/100, Step: 129/338, total loss:0.0005\n",
      "Epoch 41/100, Step: 179/338, total loss:0.0005\n",
      "Epoch 41/100, Step: 229/338, total loss:0.0004\n",
      "Epoch 41/100, Step: 279/338, total loss:0.0004\n",
      "Epoch 41/100, Step: 329/338, total loss:0.0004\n",
      "Epoch 41, accuracy: 0.9617, validation loss: 0.0242\n",
      "Epoch 42/100, Step: 41/338, total loss:0.0004\n",
      "Epoch 42/100, Step: 91/338, total loss:0.0004\n",
      "Epoch 42/100, Step: 141/338, total loss:0.0004\n",
      "Epoch 42/100, Step: 191/338, total loss:1.1170\n",
      "Epoch 42/100, Step: 241/338, total loss:1.3717\n",
      "Epoch 42/100, Step: 291/338, total loss:0.1803\n",
      "Epoch 42, accuracy: 0.9600, validation loss: 0.0249\n",
      "Epoch 43/100, Step: 3/338, total loss:0.0079\n",
      "Epoch 43/100, Step: 53/338, total loss:0.0051\n",
      "Epoch 43/100, Step: 103/338, total loss:1.3839\n",
      "Epoch 43/100, Step: 153/338, total loss:0.6863\n",
      "Epoch 43/100, Step: 203/338, total loss:0.5937\n",
      "Epoch 43/100, Step: 253/338, total loss:0.0568\n",
      "Epoch 43/100, Step: 303/338, total loss:0.6516\n",
      "Epoch 43, accuracy: 0.9500, validation loss: 0.0157\n",
      "Epoch 44/100, Step: 15/338, total loss:0.6248\n",
      "Epoch 44/100, Step: 65/338, total loss:0.0299\n",
      "Epoch 44/100, Step: 115/338, total loss:0.0148\n",
      "Epoch 44/100, Step: 165/338, total loss:0.0363\n",
      "Epoch 44/100, Step: 215/338, total loss:0.0128\n",
      "Epoch 44/100, Step: 265/338, total loss:0.0184\n",
      "Epoch 44/100, Step: 315/338, total loss:0.5545\n",
      "Epoch 44, accuracy: 0.9617, validation loss: 0.0137\n",
      "Epoch 45/100, Step: 27/338, total loss:0.9910\n",
      "Epoch 45/100, Step: 77/338, total loss:0.0387\n",
      "Epoch 45/100, Step: 127/338, total loss:0.0179\n",
      "Epoch 45/100, Step: 177/338, total loss:0.0125\n",
      "Epoch 45/100, Step: 227/338, total loss:0.0094\n",
      "Epoch 45/100, Step: 277/338, total loss:0.0073\n",
      "Epoch 45/100, Step: 327/338, total loss:0.8826\n",
      "Epoch 45, accuracy: 0.9583, validation loss: 0.0136\n",
      "Epoch 46/100, Step: 39/338, total loss:1.2840\n",
      "Epoch 46/100, Step: 89/338, total loss:1.8573\n",
      "Epoch 46/100, Step: 139/338, total loss:0.5515\n",
      "Epoch 46/100, Step: 189/338, total loss:0.5370\n",
      "Epoch 46/100, Step: 239/338, total loss:0.5194\n",
      "Epoch 46/100, Step: 289/338, total loss:0.0655\n",
      "Epoch 46, accuracy: 0.9667, validation loss: 0.0169\n",
      "Epoch 47/100, Step: 1/338, total loss:0.5736\n",
      "Epoch 47/100, Step: 51/338, total loss:1.0038\n",
      "Epoch 47/100, Step: 101/338, total loss:0.4925\n",
      "Epoch 47/100, Step: 151/338, total loss:0.0519\n",
      "Epoch 47/100, Step: 201/338, total loss:0.0200\n",
      "Epoch 47/100, Step: 251/338, total loss:0.0175\n",
      "Epoch 47/100, Step: 301/338, total loss:0.0735\n",
      "Epoch 47, accuracy: 0.9567, validation loss: 0.0210\n",
      "Epoch 48/100, Step: 13/338, total loss:0.0142\n",
      "Epoch 48/100, Step: 63/338, total loss:0.0088\n",
      "Epoch 48/100, Step: 113/338, total loss:0.0081\n",
      "Epoch 48/100, Step: 163/338, total loss:0.0071\n",
      "Epoch 48/100, Step: 213/338, total loss:0.0065\n",
      "Epoch 48/100, Step: 263/338, total loss:0.0120\n",
      "Epoch 48/100, Step: 313/338, total loss:0.0052\n",
      "Epoch 48, accuracy: 0.9567, validation loss: 0.0226\n",
      "Epoch 49/100, Step: 25/338, total loss:0.0049\n",
      "Epoch 49/100, Step: 75/338, total loss:0.0047\n",
      "Epoch 49/100, Step: 125/338, total loss:0.0042\n",
      "Epoch 49/100, Step: 175/338, total loss:0.0040\n",
      "Epoch 49/100, Step: 225/338, total loss:0.0037\n",
      "Epoch 49/100, Step: 275/338, total loss:0.0034\n",
      "Epoch 49/100, Step: 325/338, total loss:0.0034\n",
      "Epoch 49, accuracy: 0.9567, validation loss: 0.0237\n",
      "Epoch 50/100, Step: 37/338, total loss:0.1817\n",
      "Epoch 50/100, Step: 87/338, total loss:0.1014\n",
      "Epoch 50/100, Step: 137/338, total loss:0.0037\n",
      "Epoch 50/100, Step: 187/338, total loss:0.0028\n",
      "Epoch 50/100, Step: 237/338, total loss:0.0026\n",
      "Epoch 50/100, Step: 287/338, total loss:0.0028\n",
      "Epoch 50/100, Step: 337/338, total loss:0.0023\n",
      "Epoch 50, accuracy: 0.9583, validation loss: 0.0225\n",
      "Epoch 51/100, Step: 49/338, total loss:0.0024\n",
      "Epoch 51/100, Step: 99/338, total loss:0.0021\n",
      "Epoch 51/100, Step: 149/338, total loss:0.0023\n",
      "Epoch 51/100, Step: 199/338, total loss:0.0019\n",
      "Epoch 51/100, Step: 249/338, total loss:0.0019\n",
      "Epoch 51/100, Step: 299/338, total loss:0.0017\n",
      "Epoch 51, accuracy: 0.9583, validation loss: 0.0235\n",
      "Epoch 52/100, Step: 11/338, total loss:0.0015\n",
      "Epoch 52/100, Step: 61/338, total loss:0.0014\n",
      "Epoch 52/100, Step: 111/338, total loss:0.0016\n",
      "Epoch 52/100, Step: 161/338, total loss:0.0012\n",
      "Epoch 52/100, Step: 211/338, total loss:0.0015\n",
      "Epoch 52/100, Step: 261/338, total loss:0.0010\n",
      "Epoch 52/100, Step: 311/338, total loss:0.0009\n",
      "Epoch 52, accuracy: 0.9617, validation loss: 0.0244\n",
      "Epoch 53/100, Step: 23/338, total loss:0.0009\n",
      "Epoch 53/100, Step: 73/338, total loss:0.0008\n",
      "Epoch 53/100, Step: 123/338, total loss:0.0008\n",
      "Epoch 53/100, Step: 173/338, total loss:0.0008\n",
      "Epoch 53/100, Step: 223/338, total loss:0.0007\n",
      "Epoch 53/100, Step: 273/338, total loss:0.0007\n",
      "Epoch 53/100, Step: 323/338, total loss:0.0006\n",
      "Epoch 53, accuracy: 0.9617, validation loss: 0.0254\n",
      "Epoch 54/100, Step: 35/338, total loss:0.0010\n",
      "Epoch 54/100, Step: 85/338, total loss:0.0006\n",
      "Epoch 54/100, Step: 135/338, total loss:0.0006\n",
      "Epoch 54/100, Step: 185/338, total loss:0.0005\n",
      "Epoch 54/100, Step: 235/338, total loss:0.0005\n",
      "Epoch 54/100, Step: 285/338, total loss:0.0005\n",
      "Epoch 54/100, Step: 335/338, total loss:0.0004\n",
      "Epoch 54, accuracy: 0.9617, validation loss: 0.0262\n",
      "Epoch 55/100, Step: 47/338, total loss:0.0004\n",
      "Epoch 55/100, Step: 97/338, total loss:0.0004\n",
      "Epoch 55/100, Step: 147/338, total loss:0.0004\n",
      "Epoch 55/100, Step: 197/338, total loss:0.0004\n",
      "Epoch 55/100, Step: 247/338, total loss:0.0004\n",
      "Epoch 55/100, Step: 297/338, total loss:0.0004\n",
      "Epoch 55, accuracy: 0.9617, validation loss: 0.0269\n",
      "Epoch 56/100, Step: 9/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 59/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 109/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 159/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 209/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 259/338, total loss:0.0003\n",
      "Epoch 56/100, Step: 309/338, total loss:0.0003\n",
      "Epoch 56, accuracy: 0.9617, validation loss: 0.0275\n",
      "Epoch 57/100, Step: 21/338, total loss:0.0003\n",
      "Epoch 57/100, Step: 71/338, total loss:0.0003\n",
      "Epoch 57/100, Step: 121/338, total loss:0.0003\n",
      "Epoch 57/100, Step: 171/338, total loss:0.0002\n",
      "Epoch 57/100, Step: 221/338, total loss:0.0002\n",
      "Epoch 57/100, Step: 271/338, total loss:0.0002\n",
      "Epoch 57/100, Step: 321/338, total loss:0.0002\n",
      "Epoch 57, accuracy: 0.9617, validation loss: 0.0281\n",
      "Epoch 58/100, Step: 33/338, total loss:0.0002\n",
      "Epoch 58/100, Step: 83/338, total loss:0.0003\n",
      "Epoch 58/100, Step: 133/338, total loss:0.0002\n",
      "Epoch 58/100, Step: 183/338, total loss:0.0002\n",
      "Epoch 58/100, Step: 233/338, total loss:0.0002\n",
      "Epoch 58/100, Step: 283/338, total loss:0.0002\n",
      "Epoch 58/100, Step: 333/338, total loss:0.0002\n",
      "Epoch 58, accuracy: 0.9617, validation loss: 0.0287\n",
      "Epoch 59/100, Step: 45/338, total loss:0.0002\n",
      "Epoch 59/100, Step: 95/338, total loss:0.0002\n",
      "Epoch 59/100, Step: 145/338, total loss:0.0002\n",
      "Epoch 59/100, Step: 195/338, total loss:0.0002\n",
      "Epoch 59/100, Step: 245/338, total loss:0.0002\n",
      "Epoch 59/100, Step: 295/338, total loss:0.0001\n",
      "Epoch 59, accuracy: 0.9383, validation loss: 0.0492\n",
      "Epoch 60/100, Step: 7/338, total loss:1.6078\n",
      "Epoch 60/100, Step: 57/338, total loss:2.1602\n",
      "Epoch 60/100, Step: 107/338, total loss:0.1837\n",
      "Epoch 60/100, Step: 157/338, total loss:2.6302\n",
      "Epoch 60/100, Step: 207/338, total loss:2.6774\n",
      "Epoch 60/100, Step: 257/338, total loss:0.6799\n",
      "Epoch 60/100, Step: 307/338, total loss:0.1268\n",
      "Epoch 60, accuracy: 0.9600, validation loss: 0.0132\n",
      "Epoch 61/100, Step: 19/338, total loss:0.6117\n",
      "Epoch 61/100, Step: 69/338, total loss:0.0633\n",
      "Epoch 61/100, Step: 119/338, total loss:0.0130\n",
      "Epoch 61/100, Step: 169/338, total loss:0.0160\n",
      "Epoch 61/100, Step: 219/338, total loss:0.6584\n",
      "Epoch 61/100, Step: 269/338, total loss:0.5936\n",
      "Epoch 61/100, Step: 319/338, total loss:0.0608\n",
      "Epoch 61, accuracy: 0.9600, validation loss: 0.0179\n",
      "Epoch 62/100, Step: 31/338, total loss:0.0188\n",
      "Epoch 62/100, Step: 81/338, total loss:0.0233\n",
      "Epoch 62/100, Step: 131/338, total loss:0.3154\n",
      "Epoch 62/100, Step: 181/338, total loss:0.1197\n",
      "Epoch 62/100, Step: 231/338, total loss:0.0125\n",
      "Epoch 62/100, Step: 281/338, total loss:0.0109\n",
      "Epoch 62/100, Step: 331/338, total loss:0.0023\n",
      "Epoch 62, accuracy: 0.9567, validation loss: 0.0203\n",
      "Epoch 63/100, Step: 43/338, total loss:0.0070\n",
      "Epoch 63/100, Step: 93/338, total loss:0.0039\n",
      "Epoch 63/100, Step: 143/338, total loss:0.0069\n",
      "Epoch 63/100, Step: 193/338, total loss:0.0016\n",
      "Epoch 63/100, Step: 243/338, total loss:0.0033\n",
      "Epoch 63/100, Step: 293/338, total loss:0.0017\n",
      "Epoch 63, accuracy: 0.9533, validation loss: 0.0223\n",
      "Epoch 64/100, Step: 5/338, total loss:0.0031\n",
      "Epoch 64/100, Step: 55/338, total loss:0.0077\n",
      "Epoch 64/100, Step: 105/338, total loss:0.0013\n",
      "Epoch 64/100, Step: 155/338, total loss:0.0013\n",
      "Epoch 64/100, Step: 205/338, total loss:0.0012\n",
      "Epoch 64/100, Step: 255/338, total loss:0.0012\n",
      "Epoch 64/100, Step: 305/338, total loss:0.0011\n",
      "Epoch 64, accuracy: 0.9583, validation loss: 0.0219\n",
      "Epoch 65/100, Step: 17/338, total loss:0.0015\n",
      "Epoch 65/100, Step: 67/338, total loss:0.0011\n",
      "Epoch 65/100, Step: 117/338, total loss:0.0010\n",
      "Epoch 65/100, Step: 167/338, total loss:0.0010\n",
      "Epoch 65/100, Step: 217/338, total loss:0.0009\n",
      "Epoch 65/100, Step: 267/338, total loss:0.0009\n",
      "Epoch 65/100, Step: 317/338, total loss:0.0009\n",
      "Epoch 65, accuracy: 0.9583, validation loss: 0.0224\n",
      "Epoch 66/100, Step: 29/338, total loss:0.0019\n",
      "Epoch 66/100, Step: 79/338, total loss:0.0009\n",
      "Epoch 66/100, Step: 129/338, total loss:0.0008\n",
      "Epoch 66/100, Step: 179/338, total loss:0.0008\n",
      "Epoch 66/100, Step: 229/338, total loss:0.0008\n",
      "Epoch 66/100, Step: 279/338, total loss:0.0008\n",
      "Epoch 66/100, Step: 329/338, total loss:0.0007\n",
      "Epoch 66, accuracy: 0.9583, validation loss: 0.0229\n",
      "Epoch 67/100, Step: 41/338, total loss:0.0007\n",
      "Epoch 67/100, Step: 91/338, total loss:0.0007\n",
      "Epoch 67/100, Step: 141/338, total loss:0.0007\n",
      "Epoch 67/100, Step: 191/338, total loss:0.0007\n",
      "Epoch 67/100, Step: 241/338, total loss:0.0006\n",
      "Epoch 67/100, Step: 291/338, total loss:0.0007\n",
      "Epoch 67, accuracy: 0.9583, validation loss: 0.0232\n",
      "Epoch 68/100, Step: 3/338, total loss:0.0006\n",
      "Epoch 68/100, Step: 53/338, total loss:0.0006\n",
      "Epoch 68/100, Step: 103/338, total loss:0.0006\n",
      "Epoch 68/100, Step: 153/338, total loss:0.0006\n",
      "Epoch 68/100, Step: 203/338, total loss:0.0006\n",
      "Epoch 68/100, Step: 253/338, total loss:0.0005\n",
      "Epoch 68/100, Step: 303/338, total loss:0.0005\n",
      "Epoch 68, accuracy: 0.9583, validation loss: 0.0235\n",
      "Epoch 69/100, Step: 15/338, total loss:0.0005\n",
      "Epoch 69/100, Step: 65/338, total loss:0.0005\n",
      "Epoch 69/100, Step: 115/338, total loss:0.0005\n",
      "Epoch 69/100, Step: 165/338, total loss:0.0005\n",
      "Epoch 69/100, Step: 215/338, total loss:0.0005\n",
      "Epoch 69/100, Step: 265/338, total loss:0.0004\n",
      "Epoch 69/100, Step: 315/338, total loss:0.0004\n",
      "Epoch 69, accuracy: 0.9583, validation loss: 0.0238\n",
      "Epoch 70/100, Step: 27/338, total loss:0.0005\n",
      "Epoch 70/100, Step: 77/338, total loss:0.0004\n",
      "Epoch 70/100, Step: 127/338, total loss:0.0004\n",
      "Epoch 70/100, Step: 177/338, total loss:0.0004\n",
      "Epoch 70/100, Step: 227/338, total loss:0.0004\n",
      "Epoch 70/100, Step: 277/338, total loss:0.0004\n",
      "Epoch 70/100, Step: 327/338, total loss:0.0004\n",
      "Epoch 70, accuracy: 0.9583, validation loss: 0.0241\n",
      "Epoch 71/100, Step: 39/338, total loss:0.0004\n",
      "Epoch 71/100, Step: 89/338, total loss:0.0004\n",
      "Epoch 71/100, Step: 139/338, total loss:0.0004\n",
      "Epoch 71/100, Step: 189/338, total loss:0.0004\n",
      "Epoch 71/100, Step: 239/338, total loss:0.0003\n",
      "Epoch 71/100, Step: 289/338, total loss:0.0003\n",
      "Epoch 71, accuracy: 0.9583, validation loss: 0.0244\n",
      "Epoch 72/100, Step: 1/338, total loss:0.0003\n",
      "Epoch 72/100, Step: 51/338, total loss:0.0003\n",
      "Epoch 72/100, Step: 101/338, total loss:0.0009\n",
      "Epoch 72/100, Step: 151/338, total loss:0.0003\n",
      "Epoch 72/100, Step: 201/338, total loss:0.0003\n",
      "Epoch 72/100, Step: 251/338, total loss:0.0003\n",
      "Epoch 72/100, Step: 301/338, total loss:0.0003\n",
      "Epoch 72, accuracy: 0.9600, validation loss: 0.0249\n",
      "Epoch 73/100, Step: 13/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 63/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 113/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 163/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 213/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 263/338, total loss:0.0003\n",
      "Epoch 73/100, Step: 313/338, total loss:0.0002\n",
      "Epoch 73, accuracy: 0.9600, validation loss: 0.0252\n",
      "Epoch 74/100, Step: 25/338, total loss:0.0002\n",
      "Epoch 74/100, Step: 75/338, total loss:0.0188\n",
      "Epoch 74/100, Step: 125/338, total loss:1.4819\n",
      "Epoch 74/100, Step: 175/338, total loss:3.0461\n",
      "Epoch 74/100, Step: 225/338, total loss:1.0412\n",
      "Epoch 74/100, Step: 275/338, total loss:1.2763\n",
      "Epoch 74/100, Step: 325/338, total loss:1.7642\n",
      "Epoch 74, accuracy: 0.9567, validation loss: 0.0127\n",
      "Epoch 75/100, Step: 37/338, total loss:0.5746\n",
      "Epoch 75/100, Step: 87/338, total loss:0.0586\n",
      "Epoch 75/100, Step: 137/338, total loss:1.3075\n",
      "Epoch 75/100, Step: 187/338, total loss:0.1110\n",
      "Epoch 75/100, Step: 237/338, total loss:1.1973\n",
      "Epoch 75/100, Step: 287/338, total loss:0.4560\n",
      "Epoch 75/100, Step: 337/338, total loss:0.0648\n",
      "Epoch 75, accuracy: 0.9583, validation loss: 0.0203\n",
      "Epoch 76/100, Step: 49/338, total loss:0.0343\n",
      "Epoch 76/100, Step: 99/338, total loss:0.0252\n",
      "Epoch 76/100, Step: 149/338, total loss:0.4812\n",
      "Epoch 76/100, Step: 199/338, total loss:0.0256\n",
      "Epoch 76/100, Step: 249/338, total loss:0.0186\n",
      "Epoch 76/100, Step: 299/338, total loss:0.0156\n",
      "Epoch 76, accuracy: 0.9583, validation loss: 0.0223\n",
      "Epoch 77/100, Step: 11/338, total loss:0.0130\n",
      "Epoch 77/100, Step: 61/338, total loss:0.0107\n",
      "Epoch 77/100, Step: 111/338, total loss:0.0095\n",
      "Epoch 77/100, Step: 161/338, total loss:0.0081\n",
      "Epoch 77/100, Step: 211/338, total loss:0.0074\n",
      "Epoch 77/100, Step: 261/338, total loss:0.5454\n",
      "Epoch 77/100, Step: 311/338, total loss:0.0155\n",
      "Epoch 77, accuracy: 0.9583, validation loss: 0.0227\n",
      "Epoch 78/100, Step: 23/338, total loss:0.0140\n",
      "Epoch 78/100, Step: 73/338, total loss:0.0112\n",
      "Epoch 78/100, Step: 123/338, total loss:0.0096\n",
      "Epoch 78/100, Step: 173/338, total loss:0.0083\n",
      "Epoch 78/100, Step: 223/338, total loss:0.0068\n",
      "Epoch 78/100, Step: 273/338, total loss:0.5296\n",
      "Epoch 78/100, Step: 323/338, total loss:1.3270\n",
      "Epoch 78, accuracy: 0.9567, validation loss: 0.0141\n",
      "Epoch 79/100, Step: 35/338, total loss:0.6022\n",
      "Epoch 79/100, Step: 85/338, total loss:6.4950\n",
      "Epoch 79/100, Step: 135/338, total loss:8.0450\n",
      "Epoch 79/100, Step: 185/338, total loss:1.8795\n",
      "Epoch 79/100, Step: 235/338, total loss:3.1584\n",
      "Epoch 79/100, Step: 285/338, total loss:1.0528\n",
      "Epoch 79/100, Step: 335/338, total loss:0.1059\n",
      "Epoch 79, accuracy: 0.9500, validation loss: 0.0193\n",
      "Epoch 80/100, Step: 47/338, total loss:1.2287\n",
      "Epoch 80/100, Step: 97/338, total loss:0.5762\n",
      "Epoch 80/100, Step: 147/338, total loss:0.1643\n",
      "Epoch 80/100, Step: 197/338, total loss:0.0567\n",
      "Epoch 80/100, Step: 247/338, total loss:0.0377\n",
      "Epoch 80/100, Step: 297/338, total loss:0.0300\n",
      "Epoch 80, accuracy: 0.9533, validation loss: 0.0192\n",
      "Epoch 81/100, Step: 9/338, total loss:0.0765\n",
      "Epoch 81/100, Step: 59/338, total loss:0.0546\n",
      "Epoch 81/100, Step: 109/338, total loss:0.0203\n",
      "Epoch 81/100, Step: 159/338, total loss:0.4813\n",
      "Epoch 81/100, Step: 209/338, total loss:0.0262\n",
      "Epoch 81/100, Step: 259/338, total loss:0.0210\n",
      "Epoch 81/100, Step: 309/338, total loss:0.0172\n",
      "Epoch 81, accuracy: 0.9550, validation loss: 0.0200\n",
      "Epoch 82/100, Step: 21/338, total loss:0.0150\n",
      "Epoch 82/100, Step: 71/338, total loss:0.0139\n",
      "Epoch 82/100, Step: 121/338, total loss:0.0126\n",
      "Epoch 82/100, Step: 171/338, total loss:0.0131\n",
      "Epoch 82/100, Step: 221/338, total loss:0.0102\n",
      "Epoch 82/100, Step: 271/338, total loss:0.0093\n",
      "Epoch 82/100, Step: 321/338, total loss:0.0085\n",
      "Epoch 82, accuracy: 0.9550, validation loss: 0.0217\n",
      "Epoch 83/100, Step: 33/338, total loss:0.0134\n",
      "Epoch 83/100, Step: 83/338, total loss:0.0070\n",
      "Epoch 83/100, Step: 133/338, total loss:0.0063\n",
      "Epoch 83/100, Step: 183/338, total loss:0.0122\n",
      "Epoch 83/100, Step: 233/338, total loss:0.0055\n",
      "Epoch 83/100, Step: 283/338, total loss:0.0049\n",
      "Epoch 83/100, Step: 333/338, total loss:0.0047\n",
      "Epoch 83, accuracy: 0.9567, validation loss: 0.0242\n",
      "Epoch 84/100, Step: 45/338, total loss:0.0043\n",
      "Epoch 84/100, Step: 95/338, total loss:0.0041\n",
      "Epoch 84/100, Step: 145/338, total loss:0.0039\n",
      "Epoch 84/100, Step: 195/338, total loss:0.0051\n",
      "Epoch 84/100, Step: 245/338, total loss:0.0034\n",
      "Epoch 84/100, Step: 295/338, total loss:0.0033\n",
      "Epoch 84, accuracy: 0.9567, validation loss: 0.0252\n",
      "Epoch 85/100, Step: 7/338, total loss:0.0031\n",
      "Epoch 85/100, Step: 57/338, total loss:0.0030\n",
      "Epoch 85/100, Step: 107/338, total loss:0.0028\n",
      "Epoch 85/100, Step: 157/338, total loss:0.0027\n",
      "Epoch 85/100, Step: 207/338, total loss:0.0026\n",
      "Epoch 85/100, Step: 257/338, total loss:0.0024\n",
      "Epoch 85/100, Step: 307/338, total loss:0.0024\n",
      "Epoch 85, accuracy: 0.9567, validation loss: 0.0259\n",
      "Epoch 86/100, Step: 19/338, total loss:0.0022\n",
      "Epoch 86/100, Step: 69/338, total loss:0.0022\n",
      "Epoch 86/100, Step: 119/338, total loss:0.0021\n",
      "Epoch 86/100, Step: 169/338, total loss:0.0020\n",
      "Epoch 86/100, Step: 219/338, total loss:0.0019\n",
      "Epoch 86/100, Step: 269/338, total loss:0.0025\n",
      "Epoch 86/100, Step: 319/338, total loss:0.0018\n",
      "Epoch 86, accuracy: 0.9567, validation loss: 0.0265\n",
      "Epoch 87/100, Step: 31/338, total loss:0.0019\n",
      "Epoch 87/100, Step: 81/338, total loss:0.0017\n",
      "Epoch 87/100, Step: 131/338, total loss:0.0016\n",
      "Epoch 87/100, Step: 181/338, total loss:0.0016\n",
      "Epoch 87/100, Step: 231/338, total loss:0.0015\n",
      "Epoch 87/100, Step: 281/338, total loss:0.0015\n",
      "Epoch 87/100, Step: 331/338, total loss:0.0014\n",
      "Epoch 87, accuracy: 0.9567, validation loss: 0.0272\n",
      "Epoch 88/100, Step: 43/338, total loss:0.0014\n",
      "Epoch 88/100, Step: 93/338, total loss:0.0013\n",
      "Epoch 88/100, Step: 143/338, total loss:0.0013\n",
      "Epoch 88/100, Step: 193/338, total loss:0.0013\n",
      "Epoch 88/100, Step: 243/338, total loss:0.0012\n",
      "Epoch 88/100, Step: 293/338, total loss:0.0012\n",
      "Epoch 88, accuracy: 0.9567, validation loss: 0.0277\n",
      "Epoch 89/100, Step: 5/338, total loss:0.0011\n",
      "Epoch 89/100, Step: 55/338, total loss:0.0011\n",
      "Epoch 89/100, Step: 105/338, total loss:0.0011\n",
      "Epoch 89/100, Step: 155/338, total loss:0.0010\n",
      "Epoch 89/100, Step: 205/338, total loss:0.0010\n",
      "Epoch 89/100, Step: 255/338, total loss:0.0010\n",
      "Epoch 89/100, Step: 305/338, total loss:0.0010\n",
      "Epoch 89, accuracy: 0.9567, validation loss: 0.0282\n",
      "Epoch 90/100, Step: 17/338, total loss:0.0009\n",
      "Epoch 90/100, Step: 67/338, total loss:0.0009\n",
      "Epoch 90/100, Step: 117/338, total loss:0.0009\n",
      "Epoch 90/100, Step: 167/338, total loss:0.0009\n",
      "Epoch 90/100, Step: 217/338, total loss:0.0008\n",
      "Epoch 90/100, Step: 267/338, total loss:0.0008\n",
      "Epoch 90/100, Step: 317/338, total loss:0.0008\n",
      "Epoch 90, accuracy: 0.9567, validation loss: 0.0286\n",
      "Epoch 91/100, Step: 29/338, total loss:0.0008\n",
      "Epoch 91/100, Step: 79/338, total loss:0.0008\n",
      "Epoch 91/100, Step: 129/338, total loss:0.0007\n",
      "Epoch 91/100, Step: 179/338, total loss:0.0007\n",
      "Epoch 91/100, Step: 229/338, total loss:0.0007\n",
      "Epoch 91/100, Step: 279/338, total loss:0.0007\n",
      "Epoch 91/100, Step: 329/338, total loss:0.0007\n",
      "Epoch 91, accuracy: 0.9567, validation loss: 0.0291\n",
      "Epoch 92/100, Step: 41/338, total loss:0.0007\n",
      "Epoch 92/100, Step: 91/338, total loss:0.0006\n",
      "Epoch 92/100, Step: 141/338, total loss:0.0119\n",
      "Epoch 92/100, Step: 191/338, total loss:0.0006\n",
      "Epoch 92/100, Step: 241/338, total loss:0.0006\n",
      "Epoch 92/100, Step: 291/338, total loss:0.0006\n",
      "Epoch 92, accuracy: 0.9533, validation loss: 0.0311\n",
      "Epoch 93/100, Step: 3/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 53/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 103/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 153/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 203/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 253/338, total loss:0.0005\n",
      "Epoch 93/100, Step: 303/338, total loss:0.0005\n",
      "Epoch 93, accuracy: 0.9533, validation loss: 0.0315\n",
      "Epoch 94/100, Step: 15/338, total loss:0.0005\n",
      "Epoch 94/100, Step: 65/338, total loss:0.0005\n",
      "Epoch 94/100, Step: 115/338, total loss:0.0004\n",
      "Epoch 94/100, Step: 165/338, total loss:0.0004\n",
      "Epoch 94/100, Step: 215/338, total loss:0.0004\n",
      "Epoch 94/100, Step: 265/338, total loss:0.0004\n",
      "Epoch 94/100, Step: 315/338, total loss:0.0004\n",
      "Epoch 94, accuracy: 0.9533, validation loss: 0.0319\n",
      "Epoch 95/100, Step: 27/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 77/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 127/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 177/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 227/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 277/338, total loss:0.0004\n",
      "Epoch 95/100, Step: 327/338, total loss:0.0003\n",
      "Epoch 95, accuracy: 0.9533, validation loss: 0.0323\n",
      "Epoch 96/100, Step: 39/338, total loss:0.0003\n",
      "Epoch 96/100, Step: 89/338, total loss:0.0003\n",
      "Epoch 96/100, Step: 139/338, total loss:0.0003\n",
      "Epoch 96/100, Step: 189/338, total loss:0.0003\n",
      "Epoch 96/100, Step: 239/338, total loss:0.0003\n",
      "Epoch 96/100, Step: 289/338, total loss:0.0003\n",
      "Epoch 96, accuracy: 0.9533, validation loss: 0.0328\n",
      "Epoch 97/100, Step: 1/338, total loss:0.0003\n",
      "Epoch 97/100, Step: 51/338, total loss:1.8206\n",
      "Epoch 97/100, Step: 101/338, total loss:0.4727\n",
      "Epoch 97/100, Step: 151/338, total loss:0.0319\n",
      "Epoch 97/100, Step: 201/338, total loss:0.0134\n",
      "Epoch 97/100, Step: 251/338, total loss:0.0092\n",
      "Epoch 97/100, Step: 301/338, total loss:0.1777\n",
      "Epoch 97, accuracy: 0.9550, validation loss: 0.0242\n",
      "Epoch 98/100, Step: 13/338, total loss:1.2170\n",
      "Epoch 98/100, Step: 63/338, total loss:0.5569\n",
      "Epoch 98/100, Step: 113/338, total loss:0.0739\n",
      "Epoch 98/100, Step: 163/338, total loss:0.0138\n",
      "Epoch 98/100, Step: 213/338, total loss:0.0096\n",
      "Epoch 98/100, Step: 263/338, total loss:0.0074\n",
      "Epoch 98/100, Step: 313/338, total loss:0.0061\n",
      "Epoch 98, accuracy: 0.9533, validation loss: 0.0282\n",
      "Epoch 99/100, Step: 25/338, total loss:0.0052\n",
      "Epoch 99/100, Step: 75/338, total loss:0.0045\n",
      "Epoch 99/100, Step: 125/338, total loss:0.0038\n",
      "Epoch 99/100, Step: 175/338, total loss:0.0034\n",
      "Epoch 99/100, Step: 225/338, total loss:0.0032\n",
      "Epoch 99/100, Step: 275/338, total loss:0.0026\n",
      "Epoch 99/100, Step: 325/338, total loss:0.0025\n",
      "Epoch 99, accuracy: 0.9533, validation loss: 0.0295\n",
      "Epoch 100/100, Step: 37/338, total loss:0.0024\n",
      "Epoch 100/100, Step: 87/338, total loss:0.0022\n",
      "Epoch 100/100, Step: 137/338, total loss:0.0019\n",
      "Epoch 100/100, Step: 187/338, total loss:0.0019\n",
      "Epoch 100/100, Step: 237/338, total loss:0.0017\n",
      "Epoch 100/100, Step: 287/338, total loss:0.0016\n",
      "Epoch 100/100, Step: 337/338, total loss:0.0016\n",
      "Epoch 100, accuracy: 0.9533, validation loss: 0.0304\n"
     ]
    }
   ],
   "source": [
    "# 首先将模型调成训练模式\n",
    "model.train()\n",
    "\n",
    "# 清空一下cuda缓存\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 定义几个变量，帮助打印loss\n",
    "total_loss = 0.\n",
    "# 记录步数\n",
    "step = 0\n",
    "\n",
    "# 记录在验证集上最好的准确率\n",
    "best_accuracy = 0\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # 从batch中拿到训练数据\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        # 传入模型进行前向传递\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criteria(outputs.view(-1), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        step += 1\n",
    "\n",
    "        if step % log_per_step == 0:\n",
    "            print(\"Epoch {}/{}, Step: {}/{}, total loss:{:.4f}\".format(epoch+1, epochs, i, len(train_loader), total_loss))\n",
    "            total_loss = 0\n",
    "\n",
    "        del inputs, targets\n",
    "\n",
    "    # 一个epoch后，使用过验证集进行验证\n",
    "    accuracy, validation_loss = validate()\n",
    "    print(\"Epoch {}, accuracy: {:.4f}, validation loss: {:.4f}\".format(epoch+1, accuracy, validation_loss))\n",
    "    torch.save(model, model_dir / f\"model_{epoch}.pt\")\n",
    "\n",
    "    # 保存最好的模型\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model, model_dir / f\"model_best.pt\")\n",
    "        best_accuracy = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f34f03-a8d8-4e95-9035-50c473841f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载最好的模型，然后进行测试集的预测\n",
    "model = torch.load(model_dir / f\"model_best.pt\")\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d089fed-a508-4b59-bb7b-618d47cbb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MyDataset('test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc6287-4faf-4912-ae56-34b14d445b4e",
   "metadata": {},
   "source": [
    "##### 结果输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b17ee8-47d5-4171-948b-53a392fa5227",
   "metadata": {},
   "source": [
    "###### 提交需要符合提交样例结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f64925c-6471-4333-baa4-e97280a7cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for inputs, ids in test_loader:\n",
    "    outputs = model(inputs.to(device))\n",
    "    outputs = (outputs >= 0.5).int().flatten().tolist()\n",
    "    ids = ids.tolist()\n",
    "    results = results + [(id, result) for result, id in zip(outputs, ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf8323d-4718-4929-bcc2-dbc7675656f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = [pair[1] for pair in results]\n",
    "test_data['label'] = test_label\n",
    "test_data['Keywords'] = test_data['title'].fillna('')\n",
    "test_data[['uuid', 'Keywords', 'label']].to_csv('submit_task2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494001e4-fc5a-46b6-8c4d-15bf8cfc2ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
